---
title: "Unit 10 | Model Identification for Nonstationary Models"
output:
  html_document:
    df_print: paged
---

# For Live Session

```{r library-imports}

library(tidyverse)
library(tswge)
library(kableExtra)
library(tseries)
library(orcutt)

```



## Question 1 

In preparation for the live session, please complete the following and submit your PowerPoint via the online campus. Be sure and submit your work to the "Unit 10: "For Live Session" Assignment" assignment on 2DS:

Select a data set, and complete one of each model ID below:

ARIMA
Seasonal
Signal Plus Noise with Cochrane–Orcutt
Take your time series, and analyze it with these methods
Provide a slide or slides for your Key Takeaways for Unit 10!

Provide a slide or slides for any questions or comments you have from this section. This could also include topics you would like to have specifically addressed in live session! There is no minimum or maximum here.




```{r question-one-b}

# kable(head(df_texasgasprice)) %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))


```



# Asynchronous Material

## 10.1 Introduction

## 10.2 ARIMA: Model ID Setting


### 10.2.1 ARIMA Model | Model ID

- wehre phi(B) and theta(B) are the pth and qth order operators, respectively

Properties of ARIMA Models

Recall:

- The (1-B)^d factor dominates the stationary components
  - In the realizations
  - Autocorrelations
  - Sepctral densities all have peaks at f = 0

- For d > 1 this domination is even more striking
  - __Slowly damping sample autocorrelations is an indication of an ARIMA model__

$$\begin{equation}
   \phi(B)(1-B)^d(X_t - \mu) = \theta(B)a_t
\end{equation}$$


### 10.2.2  ARIMA | Dow Jones Example Part 1

Selects an AR(1) model


Question:  Should we use this (stationary) model or a model that includes a (1-B) factor?

- phi_1 is very close to 1

- Do you expect the DOWN Jones average to eventually pull back to a mean values like 16,778?
 - Historically, the answer to this last question is _No_.
 
 
A non-stationary model is suggested.


```{r 10.2.2}

data("dowjones2014")
aic.wge(dowjones2014, p=0:5, q=0:2)

```

### 10.2.3 Concept Check


True or false? Assume we use est.arma.wge to fit an ARMA(2,1) model with maximum likelihood coefficients. Assume also that we used factor.wge to look at the roots of the AR and MA factors and found that all roots were outside the unit circle. We therefore know that this data must have come from a stationary process.


(False) All models are wrong, but some are useful. The data could very well have come from a nonstationary process. We must use our intuition, domain knowledge, and others expert opinions along with the statistics to make the best decisions about the model.


## 10.3 ARIMA: Box–Jenkins Model ID Procedure, Part I


### 10.3.1 ARIMA Box-Jenkins Model ID Procedure


Steps for Obtaining an ARIMA(p,d,q) Model

1.  Difference the data (possibly multiple times) until the data appear stationary

2.  Estimate the parameters of the "stationarized data"

### 10.3.2 Model with a Unit Root

```{r 10.3.2}

### Difference the data to model it as a non-stationary model ###

# generate ARIMA(2,1,0)
x = gen.arima.wge(n = 200, phi = c(1.2, -.8), d=1, sn = 56)

plotts.sample.wge(x)

xd1.dif = artrans.wge(x, phi.tr = 1)

aic5.wge(xd1.dif, p = 0:5, q = 0:2)

est = est.ar.wge(xd1.dif, p=2)

est$avar

mean(x)


```

```{r 10.3.3}

df_bond = read.csv("./data/10_year_bond_rate_2010-2015.csv")

plotts.sample.wge(df_bond$Close)


```
```{r 10.3.4}

bd1 = artrans.wge(df_bond$Close, phi.tr = 1)

plotts.sample.wge(bd1)

```

```{r 10.3.4}

aic5.wge(bd1)

```

```{r 10.3.4}

aic5.wge(df_bond$Close)

```



## 10.4 ARIMA: Box–Jenkins Model ID Procedure, Part II

(1 - B)^2(1-1.2B + .6B^2)X_t = a_t

```{r 10.4.1}

x = gen.arima.wge(n = 200, d=2, phi=c(1.2, -.6), sn=132, vara=1)

x.d1 = artrans.wge(x, phi.tr = 1)

x.d2 = artrans.wge(x.d1, phi.tr = 1)

aic5.wge(x.d2)

```

### 10.4.2 Concept Check


If you difference the data and the differenced data still appear to be wandering and the ACF is still slowly damping with significant positive autocorrelations, you can simply difference the data again (difference the already differenced data).


_True_

### 10.4.3Concept Check

True or false? Differencing the data twice is equivalent to adding two (1-B) terms (factors) to the model.

_True_



## 10.5 ARIMA: Comments and Forecasts (Review)


Comments about ARIMA Models

There is no attraction to a mean in ARIMA modelS.  (non-stationary models)



### 10.5.2  Forecasting with ARIMA(2,1,0) Model


(1-B)(1-1.27B + .8B^2)(X_t + 21.22) = a_t; signma_2 = .93



```{r 10.5.2}

xd1 = gen.aruma.wge(n =200, phi = c(1.27, -.8), d=1)

fore.aruma.wge(xd1, d=1, phi=c(1.27, -.8), n.ahead = 50, limits =  FALSE)

```

## 10.6 ARIMA: Dow Jones Example, Part II

```{r 10.6.1}

# dow = data("dowjones2014")
# difference the data

dow.1 = artrans.wge(dowjones2014, phi.tr = 1)

aic5.wge(dow.1, p=0:5, q=0:2)
# aic picks ARMA(4,1)

est.arma.wge(dow.1, p=4, q=1)

factor.wge(phi = c(0.9265955, 0.1355600, -0.0240474, -0.1242563))
```

## 10.7 ARIMA: A More General Model ID Method—Overfit Tables

### 10.7.1 A More General Approach for Detecting Non-Stationarities


### 10.7.2 Tiao/ Tsay and Overfit Tables


Even though the data are not from an AR(6) or AR(8), the 1-B shows up in both factor tables


```{r 10.7.2}

# generate ARIMA(2,1,0) data as before
xd1 = gen.arima.wge(n = 200, phi = c(1.2, -.8), d=1, sn = 56)

# fit an AR(6) and AR(8) to this realization

est.ar.wge(xd1, p=6, type="burg")

est.ar.wge(xd1, p=8, type = "burg")



```
### 10.7.3 10-Year Bond Rate


```{r}

est.ar.wge(df_bond$Close, p=6, type="burg")

```


### 10.7.4 Two Unit Roots

- Has roots very close to the unit circle (the Abs recip)
- Has System Frequency f_0 ~ 0.00
- 1 -2B + B^2 = (1 - B)^2

```{r 10.7.4}

x = gen.arima.wge(n = 200, d=2, phi=c(1.2, -.7), sn=132)

# fit an AR(8) and AR(10) to this realization

est.ar.wge(x, p=8, type="burg")

```



### 10.7.5  Zero, One or Two Roots


```{r 10.7.5}

df_roots = read.csv("./data/zero_one_or_tworootsofone.csv")

# plotts.sample.wge(df_roots$x)

est.ar.wge(df_roots$x, p=8)


```

## 10.8 ARIMA: Testing for Unit Roots

### 10.8.1 Dicky-Fuller Test


- Popular in Economics
- Helps you to decide whether or not to include one or more (1-B) factors in your model

- They involve a test of the hypothesis

H_0 = model has a root of +1
H_A = the model does not have a root of +1

```{r 10.8.2}

x = gen.arma.wge(200,phi = c(.9), sn = 5)

adf.test(x)

```

```{r 10.8.4}

x = gen.arma.wge(200,phi = c(.99), plot = FALSE)

adf.test(x)

a = c(0.02977, 0.157, 0.2907, 0.4233, 0.03683, 0.02514,  0.01579, 0.04436,  0.2606, 0.1232)

```

## 10.9 Seasonal Models: Model Identification

### 10.9.4 Southwest Airlines Flight Data

```{r 10.9.4.1}

df_swa = read.csv("./data/swadelay.csv")

head(df_swa)

```




```{r 10.9.4.2}


factor.wge(phi = c(rep(0,11), 1))

```

```{r 10.9.4.3}


est.ar.wge(df_swa$arr_delay, p = 15, factor = TRUE, type = "burg")

```


### 10.10 Seasonal Models: Example—Airline Data

```{r 10.10.1}

x = gen.aruma.wge(n=200, s=12, phi=c(1.5, -.8), sn = 87)
x = x + 50

fore.aruma.wge(x, s=12, phi=c(1.47, -.76), n.ahead = 36, lastn = TRUE, limits = FALSE)


```

### 10.10.2 Log Airline Data

- 1 - 2B + B^2 = (1 - B)^2  which is associated with frequency f_0 = 0

- We encountered a similar situations with an ARIMA model with d = 2.

```{r 10.10.3}

data(airlog)



# 1-1.9697B+0.9704B^2    1.0149+-0.0218i      0.9851       0.0034

d1 = artrans.wge(airlog, phi.tr = 1)

d1.12 = artrans.wge(d1, phi.tr = c(rep(0,11), 1))

e = est.ar.wge(d1.12, p=12, type = "burg")
# aic5.wge(d1.12, p=0:13, q=0:3)
# aic picks an ARMA(12,1)

# aic5.wge(d1.12, p=0:13, q=0:3, type = "bic")
# bic picks an MA(1)

```

## 10.11 Seasonal Models: Example—Penn Temp Data


### 10.11.1


__Do Not__ include 1 - B^12, for example, in the model simply because there is a 12th order nonstationarity or because the data show a period of 12.

__Check the factor tables__

```{r 10.11.1}

data(patemp)

plotts.sample.wge(patemp)

est.ar.wge(patemp, p=14, type = "burg")

y.tr = artrans.wge(patemp, phi.tr = c(1.732, -1))


aic5.wge(y.tr, p=0:13, q=0:3, type = "bic")


est.ar.wge(y.tr, p=3)

mean(patemp)

```

### 10.11.2  Concept Check

True or false? If we have monthly data that, after looking at the spectral density, has a peak at .08 (1/12), we should always include a (1-B12) factor in the model.

__False__


### 10.11.3 Concept Check

True or false? If we have monthly data that, after looking at the spectral density, has a peak at .08 (1/12), we should always include a (1-B12) factor in the model.


__False__

### 10.11.4


True or false? We can fit an AR(2) model that has a frequency at .25 (or .08).

__True__


## 10.12 Signal Plus Noise Models: Testing for Trend OLS Method

- Let t = Time be the independent variable
- Let x = X_t be the dependent variable
- Consider the standard regression model
 - X_t = a + bt + Z_t
- Conclude there is a trend if H_0:b = 0 is rejected

The R program _lm_ can be used fore regression

- re = lm(formula = x~t)
- summary(le)

X_t = -2.082 + .073t + Zt


and H_0: b = 0 is rejected with p<.001. 

_unlikely to happen by chance if the null hypothesis were true_


### 10.12.2

When we have tests with inflated "observed significance rates"
   - Then if you find a significant deterministic trend, you don't have "confidence" that the trend is actually deterministic

__Type 1 Error:  We rejected when Ho: β_1=0 was true.__


```{r 10.12.2}


x =  gen.sigplusnoise.wge(100, b0 = 0, b1= 0, phi= .95, sn = 28, plot = FALSE)

t = seq(1,100,1)

df = data.frame(x = x, t = t)

fit = lm(x~t, data = df)

summary(fit)



```

```{r 10.12.5}

x = gen.sigplusnoise.wge(100, b0 = 0, b1= 0, phi= .95)  #note that there is not a seed this time. We will generate a different realization each time.
t = seq(1,100,1)
df = data.frame(x = x, t= t)
fit = lm(x~t, data = df)
summary(fit) # record whether it rejected or failed to reject. 
```

## 10.13 Signal Plus Noise Models: Testing for Trend—Cochrane-Orcutt

X_t = a + bt + _Z_t_, (1 - phi_1B)Z_t = a_t

- Steps

  1. Fit a linear regression to X_t getting estimates for a(hat), b(hat)
  
  2. Calculate Z(hat)_t = X_t - a(hat) - b(hat)_t
  Z(hat)_t should be approximately AR(1)
  
  3. Fit an AR(1) to Z(hat)_t, get estimate of phi(hat)_1
  
  4. Calculate y(hat)_t = (1 - phi(hat)B)X_t, t = 2,...,n
  
  


To Test H_0: b = 0 in this new model using standard techniques is called the Cochrane-Orcutt test

Type 1 error rate:  Probability of rejecting the null hypothesis when it is true

We typically run hypothesis tests controlling the Type Error Rate to be small (commonly alpha = 0.05)

There is a trade-off between error and power.




### 10.13.2 Cochrane-Orcutt in R

```{r 10.13.2.1}

# b1 = slope

x = gen.sigplusnoise.wge(100, b0 = 0, b1 = 0, phi = .95, sn = 21, plot = FALSE)

t = seq(1,100,1)
df = data.frame(x = x, t= t)
fit = lm(x~t, data = df)
summary(fit) # record whether it rejected or failed to reject. 


# __Type 1 Error:  We rejected when Ho: β_1=0 was true.__

```




```{r 10.13.2.2}


cfit = cochrane.orcutt(fit)
summary(cfit)

# Fail to reject the null hypothesis at a p-value of .3129 (Correct)


```

### 10.13.3


```{r 10.13.3}


# head(df_swa)

t = seq(1,177,1)
df = data.frame(x = df_swa$arr_delay, t= t)
fit = lm(x~t, data = df)
summary(fit) # record whether it rejected or failed to reject. 

```

```{r}

cfit = cochrane.orcutt(fit)
summary(cfit)

```


