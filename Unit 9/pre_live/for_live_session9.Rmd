---
title: "Unit 9 - Model Identification for Stationary Models"
output: html_notebook
---

# For Live Session

```{r library-imports}

library(tidyverse)
library(tswge)

```



## Question 1 

In preparation for the next live session, complete the following. Be sure and submit your work to the "Unit 9: "For Live Session" Assignment" assignment on 2DS:

Please address each activity on at least one PowerPoint slide and submit via the online campus. 

Using the Texas gas price data (`TexasGasPrices.csv`), we found that an AR(2) was the model suggested by both the AIC and BIC. We would now like to compare the fit from using the maximum likelihood and Burg estimates. 

Provide as much detail as you need to adequately describe the question of interest. For example

- Provide detail and context, in addition to a number, for questions asking for an estimate.
- You may/should provide code (because your audience is your peers).
- You should provide adequate labels.
- Any other pertinent details to sufficiently convey your response.


Using at least one slide per question

- Fit an AR(2) to the data using the maximum likelihood estimates like you did in the Concept Check question.
- Fit and AR(2) to the data using the Burg estimates.  Display and describe.
- Find the ASE for the maximum likelihood fit by forecasting the last 24 weeks of the series.
- Find the ASE for the Burg fit by forecasting the last 24 weeks of the series.
- Which model would you choose?



# Asynchronous Material

## 9.1 Introduction

### Introduction and Setting


**Model Free Methods**

- Windowed spectral estimators
- Sample autocorrelations
- Filtering procedures


**Model Dependent Techniques**

- AR models
- Signal-plus-noise models
- ARMA models
- ARIMA models
- Seasonal models

## 9.2 Estimation: Introduction

### Estimation Methods for Stationary Models

  `est.arma.wge`
    - Maximum likelihood estimation only
  `est.ar.wge`
    - Maximum likelihood
    - Yule-Walker
    - Burger
    
    
- For ARMA(p,q) models with q > 0, tswge only produces maximum likelihood estimates.

- For AR(p) models, tswge provides ML, YW. and Burg estimates



    
## 9.3 Estimation: Maximum Likelihood Estimation

### 9.3.1  

- Involves maximizing the likelihood function L = f(x_1, x_2, ..., x_n), which is the joint distribution of the time series realization

- Iterative, computationally intensive procedure

- Involves distributional assumptions about white noise (we will assume normal white noise)

- Is applicable to AR(p), MA(q) and ARMA(p,q) models


### 9.3.2 tswge

The key function for ML estimation in an ARMA model is `est.arma.wge`(data, p, q)

Type:  

- mle (only)

However, if you know that the model is an AR(p) model, then you can use

`est.ar.wge`(data, p, q, type)

Types:

- mle (default)
- yw
- burg


Final Model Estimation

$$\begin{equation}
   (1 - 1.64B + .81B^2)(X_t - 49.96) = (1 - .87B)a_t ;  \sigma^2_a = 5.19
\end{equation}$$

```{r 9.3.2.1}

# ARMA(2,1)

# (1 - 1.6B + .8B^2)(X_t - 50) = (1 - .8B)a_t, sigma_squared = 5

x21 = gen.arma.wge(n=100, phi = c(1.6, -.8), theta = .8, vara = 5, sn = 55, plot = FALSE)
x21 = x21 + 50 # gen.arma generates data from a zero mean model.  
plot.ts(x21)
# We use this strategy to generate the AR(2) model with mean 50.
est.arma.wge(x21, p=2, q=1)
mean(x21)


```

Final Model Estimation

$$\begin{equation}
   (1 - .06B + .69B^2 - .11B^3 + .68B^4)(X_t - 19.98) = a_t ;  \sigma^2_a = 8.78
\end{equation}$$



```{r 9.3.2.2}

# ARMA(2,1)

# (1 + .7B^2 - .1B^3 + .72B^4)(X_t - 20) = a_t, sigma_squared = 10

x21 = gen.arma.wge(n=100, phi = c(0, -.7, .1, -.72), vara = 4, sn = 72, plot = FALSE)
x21 = x21 + 20 # gen.arma generates data from a zero mean model.  
plot.ts(x21)
# We use this strategy to generate the AR(2) model with mean 50.
est.arma.wge(x21, p=4, q=1)
mean(x21)


```


```{r 9.3.3}

# ARMA(2,1)

# (1 - .3B + .7B^2)(X_t - 37) = (1 + .4B)a_t, sigma_squared = 4

x21 = gen.arma.wge(n=200, phi = c(.3, -.7), theta = -.4, vara = 4, sn = 27, plot = FALSE)
x21 = x21 + 37 # gen.arma generates data from a zero mean model.  
plot.ts(x21)
# We use this strategy to generate the AR(2) model with mean 50.
est.arma.wge(x21, p=2, q=1)
mean(x21)



```
    
## 9.4 Estimation: Yule–Walker Estimates

Change p_k to p_k (hat) and solve the resulting system of equations for phi_1_hat, ..., phi_p_hat


These are the Yule-Walker estimates


## 9.5 Estimation: Burg Estimates

In AR models, there is no preference in time direction (recall p_k = p_-k)

Goal is to minimize forward-backward least squares.

Burg showed how to miminize the forward-backward least squares, while at the same time assuring a stationary solution.

### 9.4.4

- Maximum likelihood estimation

_Estimates found by finding the values that provide the largest value of the joint distribution of the time series realization. This is an iterative procedure._

- Yule–Walker estimation

_Estimates found by solving a system of linear equations by estimating the autocorrelations._

- Burg estimation

_Estimates found by minimizing the forward backward least squares._

Match the estimation models to the correct description.

### 9.5.5   

Which estimates can estimate parameters from both stationary and nonstationary models?

_Maximum likelihood estimates_


### 9.5.6

```{r 9.5.6}

# Generate Data from an AR(2):  (1 - 1.6B + .9B^2)X_t = a_t

x = gen.arma.wge(n = 200, phi = c(1.6, -.9), vara = 37, sn = 33)
plotts.wge(x)

# Yule-Walker Estimates
x.yw = est.ar.wge(x, p=2, type = "yw")
x.yw

# Burg Estimates
x.burg = est.ar.wge(x, p=2, type="burg")
x.burg


# Maximum Likelihood Estimates
x.mle = est.ar.wge(x, p=2, type="mle")
x.mle

```


### 9.5.7

```{r 9.5.7}

# Generate Data from an AR(2):  (1 - .3B + .7B^2)(X_t - 37) = (1 + .4B)a_t  ; sigma_2 = 4

x = gen.arma.wge(n = 200, phi = c(.3, -.7), theta = -.4, vara = 4, sn = 33, plot = FALSE)
x = x + 37
plotts.wge(x)

# Maximum Likelihood Estimates
x.mle= est.arma.wge(x, p=2, q = 1)
x.mle


```

### 9.5.8

```{r 9.5.8}

# Generate Data from an AR(2):  (1 - .3B + .7B^2)(X_t - 37) = a_t  ; sigma_2 = 4

x = gen.arma.wge(n = 200, phi = c(.3, -.7), vara = 4, sn = 33, plot = FALSE)
x = x + 37
plotts.wge(x)

# Burg Estimates
x.burg = est.ar.wge(x, p=2, type = "burg")
x.burg


```

## 9.6 Estimation: When It Makes a Difference

### 9.6.1

When the real roots are close to the unit circle, the Yule-Walker method does not perform well.

### 9.6.2

Models should not be used when roots are found to be inside the unit circle, this would indicate a non-stationary model.

Burg and Yule-Walker methods will always produce a stationary model.    

### 9.6.3

Which of the following statements is `FALSE`?

_Burg estimates may find a nonstationary model (produce roots inside the unit circle)._

## 9.7 Estimation: Noise Variance

```{r 9.7.1}

# Generate Data from an AR(2):  (1 - .3B + .7B^2)(X_t - 37) = a_t  ; sigma_2 = 4

x = gen.arma.wge(n = 100, phi = c(2.195, -1.994, .696), vara = 1, sn = 53, plot = TRUE)
plotts.wge(x)

x.mle = est.ar.wge(x, p=3, type = "mle")
x.mle$avar

mean(x.mle$res^2)


```

## 9.8 Model Identification: Introduction

Lesson:  Always plot the data.

- Check for white noise in the time series plot and via the ACF.

### 9.8.3


```{r 9.8.3}

df_white_noise = read.csv("./maybewhitenoise1.csv")
# head(df_white_noise)
plotts.wge(df_white_noise$x)
acf(df_white_noise$x)

```
### 9.8.4
```{r 9.8.4}

df_white_noise = read.csv("./maybewhitenoise2.csv")
# head(df_white_noise)
plotts.wge(df_white_noise$x)
acf(df_white_noise$x)

```

## 9.9 Model Identification: AIC Type, Part I



